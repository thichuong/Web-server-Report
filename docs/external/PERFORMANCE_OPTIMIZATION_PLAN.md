# üöÄ PH∆Ø∆†NG √ÅN T·ªêI ∆ØU HI·ªÜU SU·∫§T WEB SERVER

## 1. üîß T·ªêI ∆ØU TOKIO RUNTIME & THREADING

### A. C·∫•u h√¨nh Tokio Runtime t·ªëi ∆∞u
```rust
// Trong main.rs - thay #[tokio::main]
fn main() -> Result<(), anyhow::Error> {
    // T·ªëi ∆∞u runtime cho high-performance workload
    let rt = tokio::runtime::Builder::new_multi_thread()
        .worker_threads(num_cpus::get()) // S·ª≠ d·ª•ng t·∫•t c·∫£ CPU cores
        .max_blocking_threads(num_cpus::get() * 4) // TƒÉng blocking threads
        .enable_all()
        .thread_name("tokio-worker")
        .thread_stack_size(4 * 1024 * 1024) // 4MB stack
        .build()?;

    rt.block_on(async_main())
}
```

### B. Thread Pool cho CPU-intensive tasks
```rust
// S·ª≠ d·ª•ng dedicated thread pool cho heavy computations
lazy_static::lazy_static! {
    static ref CPU_POOL: threadpool::ThreadPool = {
        threadpool::Builder::new()
            .num_threads(num_cpus::get())
            .thread_name("cpu-worker".into())
            .build()
    };
}
```

## 2. üìä T·ªêI ∆ØU DATABASE & CACHING

### A. Connection Pool t·ªëi ∆∞u
```rust
// Trong main.rs - t·ªëi ∆∞u connection pool
let pool = sqlx::postgres::PgPoolOptions::new()
    .max_connections(num_cpus::get() * 4) // 4x CPU cores
    .min_connections(num_cpus::get())     // √çt nh·∫•t 1 connection/core
    .max_lifetime(Duration::from_secs(1800)) // 30 ph√∫t
    .idle_timeout(Duration::from_secs(600))  // 10 ph√∫t idle
    .acquire_timeout(Duration::from_secs(10)) // Gi·∫£m timeout
    .test_before_acquire(false) // T·∫Øt test connection ƒë·ªÉ tƒÉng t·ªëc
    .connect(&database_url).await?;
```

### B. Multi-level Caching Strategy
```rust
use moka::future::Cache;

pub struct AdvancedCache {
    // L1: In-memory cache (fastest)
    l1_reports: Cache<i32, Arc<Report>>,
    l1_dashboard: Cache<String, Arc<DashboardSummary>>,
    
    // L2: Redis cache (medium speed)
    redis: RedisPool,
    
    // L3: Database (slowest)
    db: PgPool,
}
```

## 3. üîÑ T·ªêI ∆ØU X·ª¨ L√ù B·∫§T ƒê·ªíNG B·ªò

### A. Concurrent Request Processing
```rust
// X·ª≠ l√Ω nhi·ªÅu requests ƒë·ªìng th·ªùi
async fn handle_concurrent_requests(requests: Vec<Request>) -> Vec<Response> {
    futures::future::join_all(
        requests.into_iter().map(|req| async move {
            tokio::spawn(async move {
                process_request(req).await
            }).await.unwrap_or_else(|_| default_error_response())
        })
    ).await
}
```

### B. Stream Processing cho Large Data
```rust
use tokio_stream::StreamExt;
use futures::stream::FuturesUnordered;

async fn stream_process_reports() -> Result<impl Stream<Item = Report>> {
    sqlx::query_as::<_, Report>("SELECT * FROM reports ORDER BY created_at DESC")
        .fetch(&pool)
        .map(|result| async move {
            match result {
                Ok(report) => process_report_async(report).await,
                Err(e) => Err(e.into())
            }
        })
        .buffer_unordered(num_cpus::get()) // Process N reports concurrently
}
```

## 4. üì° T·ªêI ∆ØU WEBSOCKET & REAL-TIME

### A. WebSocket Connection Pooling
```rust
pub struct WebSocketPool {
    connections: DashMap<String, Arc<WebSocketConnection>>,
    broadcast_channels: DashMap<String, broadcast::Sender<Message>>,
}

impl WebSocketPool {
    pub async fn broadcast_to_room(&self, room: &str, message: Message) {
        if let Some(sender) = self.broadcast_channels.get(room) {
            let _ = sender.send(message);
        }
    }
}
```

### B. Batched Broadcasting
```rust
async fn batch_broadcast_updates(updates: Vec<Update>) {
    // Group updates by type
    let mut batched: HashMap<UpdateType, Vec<Update>> = HashMap::new();
    
    for update in updates {
        batched.entry(update.update_type).or_default().push(update);
    }
    
    // Broadcast each batch concurrently
    futures::future::join_all(
        batched.into_iter().map(|(update_type, batch)| async move {
            broadcast_batch(update_type, batch).await
        })
    ).await;
}
```

## 5. üéØ T·ªêI ∆ØU API CALLS & HTTP

### A. HTTP Client v·ªõi Connection Reuse
```rust
pub fn create_optimized_client() -> reqwest::Client {
    reqwest::Client::builder()
        .timeout(Duration::from_secs(10))
        .pool_max_idle_per_host(20)
        .pool_idle_timeout(Duration::from_secs(30))
        .tcp_keepalive(Duration::from_secs(60))
        .http2_prior_knowledge()
        .build()
        .expect("Failed to create HTTP client")
}
```

### B. API Call Deduplication
```rust
use tokio::sync::Mutex;
use std::collections::HashMap;

pub struct ApiCallDeduplicator {
    pending_calls: Mutex<HashMap<String, tokio::sync::watch::Receiver<ApiResult>>>,
}

impl ApiCallDeduplicator {
    pub async fn get_or_fetch(&self, key: String, fetcher: impl Future<Output = ApiResult>) -> ApiResult {
        let mut pending = self.pending_calls.lock().await;
        
        if let Some(receiver) = pending.get(&key) {
            // Duplicate call - wait for existing request
            receiver.borrow().clone()
        } else {
            // New call - execute and cache
            let (tx, rx) = tokio::sync::watch::channel(ApiResult::Pending);
            pending.insert(key.clone(), rx.clone());
            drop(pending);
            
            let result = fetcher.await;
            let _ = tx.send(result.clone());
            
            // Clean up
            self.pending_calls.lock().await.remove(&key);
            result
        }
    }
}
```

## 6. üîç T·ªêI ∆ØU TEMPLATE RENDERING

### A. Template Precompilation
```rust
use rayon::prelude::*;

async fn render_templates_parallel(
    templates: Vec<TemplateData>
) -> Result<Vec<String>, tera::Error> {
    let rendered: Result<Vec<_>, _> = tokio::task::spawn_blocking(move || {
        templates.into_par_iter()
            .map(|template_data| {
                TERA.render(&template_data.name, &template_data.context)
            })
            .collect()
    }).await.unwrap();
    
    rendered
}
```

### B. Template Caching v·ªõi Invalidation
```rust
pub struct TemplateCache {
    cache: moka::future::Cache<String, String>,
    dependencies: DashMap<String, Vec<String>>,
}

impl TemplateCache {
    pub async fn get_or_render(&self, template: &str, context: &Context) -> Result<String> {
        let cache_key = format!("{}:{}", template, context.hash());
        
        if let Some(cached) = self.cache.get(&cache_key).await {
            return Ok(cached);
        }
        
        let rendered = tokio::task::spawn_blocking({
            let template = template.to_owned();
            let context = context.clone();
            move || TERA.render(&template, &context)
        }).await??;
        
        self.cache.insert(cache_key, rendered.clone()).await;
        Ok(rendered)
    }
}
```

## 7. üìà MONITORING & METRICS

### A. Performance Metrics Collection
```rust
use prometheus::{Counter, Histogram, Gauge};

lazy_static::lazy_static! {
    static ref REQUEST_COUNTER: Counter = Counter::new("requests_total", "Total requests").unwrap();
    static ref REQUEST_DURATION: Histogram = Histogram::new("request_duration_seconds", "Request duration").unwrap();
    static ref ACTIVE_CONNECTIONS: Gauge = Gauge::new("active_connections", "Active connections").unwrap();
}
```

### B. Health Check v·ªõi Circuit Breaker
```rust
use circuit_breaker::{CircuitBreaker, CircuitBreakerConfig};

pub struct HealthChecker {
    db_breaker: CircuitBreaker,
    redis_breaker: CircuitBreaker,
    api_breaker: CircuitBreaker,
}

impl HealthChecker {
    pub async fn check_system_health(&self) -> SystemHealth {
        let (db_health, redis_health, api_health) = tokio::join!(
            self.check_database(),
            self.check_redis(), 
            self.check_external_apis()
        );
        
        SystemHealth {
            database: db_health,
            cache: redis_health,
            external_apis: api_health,
        }
    }
}
```

## 8. üöÄ DEPLOYMENT T·ªêI ∆ØU

### A. Dockerfile t·ªëi ∆∞u
```dockerfile
# Multi-stage build v·ªõi optimization
FROM rust:1.75-slim as builder

WORKDIR /app
COPY . .

# T·ªëi ∆∞u compile time
ENV RUSTFLAGS="-C target-cpu=native"
RUN cargo build --release --locked

FROM debian:bookworm-slim
RUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*

COPY --from=builder /app/target/release/web-server-report /usr/local/bin/

# T·ªëi ∆∞u runtime environment
ENV RUST_LOG=info
ENV TOKIO_THREAD_STACK_SIZE=4194304

EXPOSE 8000
CMD ["web-server-report"]
```

### B. Configuration Tuning
```toml
# Cargo.toml optimizations
[profile.release]
opt-level = 3           # Maximum optimization
lto = "fat"            # Full LTO
codegen-units = 1      # Single codegen unit for better optimization
panic = "abort"        # Abort on panic (smaller binary)
strip = true          # Strip debug symbols
```

## üìä K·∫æT QU·∫¢ MONG ƒê·ª¢I:

1. **Throughput**: TƒÉng 300-500% requests/second
2. **Latency**: Gi·∫£m 50-70% response time
3. **Memory Usage**: Gi·∫£m 20-30% memory footprint  
4. **CPU Efficiency**: TƒÉng 40-60% CPU utilization
5. **Concurrent Users**: H·ªó tr·ª£ 10,000+ concurrent connections
6. **Database Performance**: Gi·∫£m 60% query time
7. **Cache Hit Rate**: ƒê·∫°t 85-95% hit rate
