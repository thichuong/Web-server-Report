# Web Server Report - High-Performance Crypto Dashboard

üöÄ **Ultra-fast Rust web server** achieving **16,829+ RPS** with **5.2ms latency** for crypto investment reports with advanced multi-threading, Cache Stampede Protection, and real-time features.

## ‚ú® Key Features

### üéØ Core Functionality
- **Interactive Crypto Reports**: Dynamic investment reports with Chart.js visualizations
- **Multi-language Support**: Vietnamese/English with seamless switching
- **Responsive Design**: Mobile-first, adaptive UI
- **PDF Generation**: Export reports to PDF format
- **Real-time Updates**: WebSocket integration for live data
- **API Resilience**: Binance + CoinGecko + CoinMarketCap fallback system for 99.9% uptime

### ‚ö° Performance Optimizations
- **Cache Stampede Protection**: DashMap+Mutex request coalescing for L2, Moka's get_with() for L1
- **Multi-tier Cache System**: L1 (In-Memory) + L2 (Redis) with automatic promotion
- **Multi-threaded Architecture**: Thread-safe operations with concurrent processing  
- **Concurrent Request Processing**: Handle 16,829+ RPS with 5.2ms average latency
- **Lock-free Operations**: Atomic counters and non-blocking data structures
- **Parallel CPU Tasks**: Background template rendering with spawn_blocking
- **Unified Cache Manager**: Single API for all caching operations with stampede protection
- **Database Connection Pool**: Optimized for 16-core systems (32 max connections)
- **Chart Module Bundling**: Optimized JavaScript asset delivery

### üõ°Ô∏è Reliability Features
- **Automatic API Fallback**: Binance ‚Üí CoinGecko ‚Üí CoinMarketCap seamless switching
- **Data Validation**: Prevents corrupted data from affecting reports
- **Cache-first Data Strategy**: Cache persistence v·ªõi intelligent API fallback logic
- **Circuit Breaker Pattern**: Automatic recovery from API failures
- **Source Attribution**: Track which APIs provided data for debugging

### üîß Technical Stack
- **Backend**: Rust + Axum (high-performance async web framework)
- **Database**: PostgreSQL with optimized connection pooling (32 max connections)
- **Caching**: Multi-tier L1 (moka) + L2 (Redis) with Cache Stampede Protection
- **Market Data**: Binance (primary) + CoinGecko + CoinMarketCap (fallback) + TAAPI.io + Finnhub (US stocks)
- **Concurrency**: Rayon ThreadPool + tokio async runtime + DashMap request coalescing
- **Real-time**: Redis + WebSocket for live updates
- **Templates**: Tera template engine with background rendering
- **Frontend**: Vanilla JS with Chart.js and modern CSS
- **API Resilience**: Multi-source data with Binance + CoinGecko + CoinMarketCap fallback + Finnhub US stocks

## üöÄ Quick Start

### Prerequisites
- Rust 1.70+ ([Install Rust](https://rustup.rs/))
- PostgreSQL database
- Redis server (optional, for WebSocket features)
- CoinMarketCap API key (optional, for fallback support)
- Finnhub API key (optional, for US stock market indices)

### 1. Clone & Setup
```bash
git clone https://github.com/thichuong/Web-server-Report.git
cd Web-server-Report

# Copy environment template
cp .env.example .env
```

### 2. Configure Environment
Edit `.env` with your settings:
```env
# Database connection
DATABASE_URL=postgresql://username:password@localhost:5432/database_name

# Security
AUTO_UPDATE_SECRET_KEY=your_secret_key_here

# External APIs
TAAPI_SECRET=your_taapi_secret_for_crypto_data
CMC_API_KEY=your_coinmarketcap_api_key_here    # Optional - enables crypto fallback support
FINNHUB_API_KEY=your_finnhub_api_key_here      # Optional - enables US stock market data

# Optional: Redis for WebSocket/caching (defaults to localhost:6379)
REDIS_URL=redis://localhost:6379

# Server configuration
HOST=0.0.0.0
PORT=8000

# Development mode (enables debug logging)
DEBUG=1
```

### 3. Build & Run
```bash
# Development build
cargo run

# Production build (optimized)
cargo build --release
./target/release/web-server-report
```

Server will start at `http://localhost:8000` üéâ

## üèóÔ∏è Architecture & Performance

### üÜï Recent Upgrades (Latest)

#### Redis Streams Integration (Real-time Data Pipeline)
- **üì§ Stream Publishing**: Market data automatically published to Redis Streams for external consumers
- **üîÑ Bi-directional Communication**: Layer 3 publishes to streams, enables Python AI service consumption
- **‚ö° Sub-millisecond Publishing**: Non-blocking stream writes with <1ms overhead
- **üéØ Consumer-Ready Format**: Flattened JSON key-value pairs optimized for stream consumers
- **üõ°Ô∏è Fault Tolerance**: Stream publishing failures don't affect core functionality
- **üìä Stream Monitoring**: Track stream health via `/health` endpoint

#### Layer 1 Infrastructure Enhancements
- **üóÇÔ∏è Cache Manager Redis Streams**: Native Redis Stream methods in CacheManager
  - `publish_to_stream()`: XADD with automatic trimming support
  - `read_stream_latest()`: Retrieve N latest entries (newest first)
  - `read_stream()`: Blocking/non-blocking stream consumption with XREAD
- **üèùÔ∏è App State Island**: Unified application state management with Redis Streams support
- **üì¶ Chart Modules Island**: Optimized JavaScript bundling with cache integration
- **üîß Shared Components**: Template registry and utilities across all layers

#### Layer 2 External Services Improvements
- **üåê External APIs Island**: Enhanced circuit breaker with stream publishing
- **üíæ Cache-first Strategy**: API responses cached before stream publishing
- **üîÑ Multi-source Fallback**: Binance ‚Üí CoinGecko ‚Üí CoinMarketCap with stream integration
- **üì° US Stock Data**: Finnhub integration with stream publishing for indices

#### Layer 3 Communication Upgrades
- **üìä Market Data Adapter**: 
  - Automatic Redis Streams publishing after Layer 2 data fetch
  - Stream entry ID tracking for debugging
  - Non-critical error handling (continues on stream failure)
- **üîå WebSocket Service**: Ready for Redis Streams consumer integration (Phase 3)
- **üí¨ Dashboard Communication**: Stream-aware data routing
- **üåâ Layer 2 Adapters**: Clean API abstraction with stream publishing

### Service Islands Architecture
H·ªá th·ªëng s·ª≠ d·ª•ng **Service Islands Architecture** - ki·∫øn tr√∫c ph√¢n t·∫ßng 5 l·ªõp v·ªõi separation of concerns r√µ r√†ng:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Layer 5: Business Logic                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  Dashboard      ‚îÇ    ‚îÇ     Crypto Reports              ‚îÇ‚îÇ
‚îÇ  ‚îÇ  Island         ‚îÇ    ‚îÇ     Island                      ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Market Data   ‚îÇ    ‚îÇ ‚Ä¢ Report Management             ‚îÇ‚îÇ
‚îÇ  ‚îÇ   Processing    ‚îÇ    ‚îÇ ‚Ä¢ Template Orchestration        ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ WebSocket     ‚îÇ    ‚îÇ ‚Ä¢ Cache Integration             ‚îÇ‚îÇ
‚îÇ  ‚îÇ   Integration   ‚îÇ    ‚îÇ                                 ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Layer 4: Observability                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ              Health System Island                      ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Component Health Monitoring                          ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ System Status Reporting                              ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Inter-layer Health Validation                        ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Layer 3: Communication                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  WebSocket      ‚îÇ    ‚îÇ    Data Communication          ‚îÇ‚îÇ
‚îÇ  ‚îÇ  Service        ‚îÇ    ‚îÇ    Service                      ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Real-time     ‚îÇ    ‚îÇ ‚Ä¢ Database Operations           ‚îÇ‚îÇ
‚îÇ  ‚îÇ   Communication ‚îÇ    ‚îÇ ‚Ä¢ Cache Integration             ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Broadcasting  ‚îÇ    ‚îÇ ‚Ä¢ Data Models                   ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Layer 2: External Services                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ              External APIs Island                      ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Market Data API (Binance, CoinGecko, CoinMarketCap) ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ US Stock Indices (Finnhub)                          ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Cache-first Strategy with Data Persistence          ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ API Aggregator (Multi-source data + Cache storage)  ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Circuit Breaker (Fault tolerance)                   ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Layer 1: Infrastructure                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  Shared         ‚îÇ    ‚îÇ    Cache System                 ‚îÇ‚îÇ
‚îÇ  ‚îÇ  Components     ‚îÇ    ‚îÇ    Island                       ‚îÇ‚îÇ
‚îÇ  ‚îÇ  Island         ‚îÇ    ‚îÇ ‚Ä¢ L1 Cache (Moka)              ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Template      ‚îÇ    ‚îÇ   - 2000 entries, 5min TTL     ‚îÇ‚îÇ
‚îÇ  ‚îÇ   Registry      ‚îÇ    ‚îÇ ‚Ä¢ L2 Cache (Redis)             ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Model         ‚îÇ    ‚îÇ   - 1hr default TTL            ‚îÇ‚îÇ
‚îÇ  ‚îÇ   Registry      ‚îÇ    ‚îÇ ‚Ä¢ Cache Manager                ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Utilities     ‚îÇ    ‚îÇ   - Unified interface          ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ ‚Ä¢ Cache Strategies              ‚îÇ‚îÇ
‚îÇ                         ‚îÇ   - ShortTerm, MediumTerm       ‚îÇ‚îÇ
‚îÇ                         ‚îÇ   - LongTerm, RealTime          ‚îÇ‚îÇ
‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Generic Cache Architecture (Layer Separation)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 2: Business Logic (API-specific implementations)     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ fetch_btc_price() ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ CacheStrategy::ShortTerm (5min)     ‚îÇ
‚îÇ fetch_rsi_data() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ CacheStrategy::LongTerm (3hr)       ‚îÇ
‚îÇ fetch_fear_greed() ‚îÄ‚îÄ‚îÄ‚ñ∫ CacheStrategy::RealTime (30s)       ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ Business-aware wrappers
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 1: Infrastructure (Generic cache functions)          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ cache_get(key) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ
‚îÇ set_with_strategy(key, value, strategy) ‚îÄ‚îê                 ‚îÇ
‚îÇ cache_data(key, value, ttl) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∫ L1+L2 Cache ‚îÇ
‚îÇ                                           ‚îÇ                 ‚îÇ
‚îÇ Generic Strategies:                       ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ ShortTerm, MediumTerm, LongTerm        ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ RealTime, Custom(Duration), Default    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                           ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                                             ‚îÇ
                    ‚ñº                                             ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   L1: moka       ‚îÇ                          ‚îÇ   L2: Redis      ‚îÇ
        ‚îÇ   (In-Memory)    ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ Promotion ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ   (Distributed)  ‚îÇ
        ‚îÇ ‚Ä¢ 2000 entries   ‚îÇ                          ‚îÇ ‚Ä¢ Persistence    ‚îÇ
        ‚îÇ ‚Ä¢ 5min TTL       ‚îÇ                          ‚îÇ ‚Ä¢ 1hr default    ‚îÇ
        ‚îÇ ‚Ä¢ <1ms response  ‚îÇ                          ‚îÇ ‚Ä¢ 2-5ms response ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Request Flow Through Service Islands
```
Client Request ‚îÄ‚îÄ‚îÄ‚ñ∫ Axum Router
                           ‚îÇ
                           ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Layer 5: Business     ‚îÇ ‚îÄ‚îÄ‚ñ∫ Template Rendering
              ‚îÇ   ‚Ä¢ Dashboard Island    ‚îÇ     Report Processing
              ‚îÇ   ‚Ä¢ Crypto Reports      ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ Business Logic Processing
                        ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Layer 3: Comm        ‚îÇ ‚îÄ‚îÄ‚ñ∫ PostgreSQL
              ‚îÇ   ‚Ä¢ Data Communication ‚îÇ     WebSocket Broadcasting
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ Data Fetching
                        ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Layer 2: External    ‚îÇ ‚îÄ‚îÄ‚ñ∫ Binance API
              ‚îÇ   ‚Ä¢ APIs Island        ‚îÇ     TaApi.io API  
              ‚îÇ   ‚Ä¢ Cache-first        ‚îÇ     Circuit Breaker
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ Cache Integration
                        ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Layer 1: Cache       ‚îÇ ‚îÄ‚îÄ‚ñ∫ L1 (moka) ‚ö°<1ms + Stampede Protection
              ‚îÇ   ‚Ä¢ Generic Strategies ‚îÇ     L2 (Redis) üî•2-5ms + Request Coalescing
              ‚îÇ   ‚Ä¢ Unified Manager    ‚îÇ     Cache Miss üíª200ms+ (single request only)
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Service Islands Performance Metrics

#### Redis Streams Performance (NEW)
- **üì§ Publish Latency**: <1ms average (non-blocking XADD)
- **üìä Stream Throughput**: 10,000+ entries/sec sustained
- **üîÑ Consumer Lag**: Sub-second for Python AI service integration
- **üíæ Stream Retention**: Auto-trimming at 1000 entries (configurable)
- **üéØ Field Encoding**: Flattened JSON ‚Üí Stream fields in <0.5ms

#### Cache Performance (Layer 1 Infrastructure) - **with Cache Stampede Protection**
- **L1 Hit Rate**: ~90% (sub-millisecond response)
- **L2 Hit Rate**: ~75% (2-5ms with automatic L1 promotion)  
- **Stampede Protection**: 99.6% improvement in high-concurrency scenarios
- **Request Coalescing**: DashMap+Mutex for L2, Moka's get_with() for L1
- **Overall Coverage**: ~95% (gi·∫£m 95% external API calls)
- **Generic Strategies**: ShortTerm(5min), MediumTerm(1hr), LongTerm(3hr), RealTime(30s)

#### Business Logic Performance (Layer 5)
- **Dashboard Island**: Real-time market data processing v·ªõi WebSocket integration
- **Crypto Reports Island**: Template orchestration v·ªõi multi-tier caching
- **Report Generation**: Background processing v·ªõi spawn_blocking

#### Communication Layer Performance (Layer 3) 
- **WebSocket Service**: Real-time broadcasting t·ªõi multiple clients
- **Data Communication**: PostgreSQL connection pool (32 max connections)
- **Cache Integration**: L2 cache cho database queries

#### External Services Performance (Layer 2)
- **Cache-first Strategy**: Binance API primary v·ªõi cache persistence
- **Circuit Breaker**: Fault tolerance cho external APIs
- **API Aggregator**: Multi-source data v·ªõi intelligent failover v√† cache storage

#### Infrastructure Performance (Layer 1)
- **üöÑ 16,829+ RPS**: Handle 16,829+ concurrent requests per second with Cache Stampede Protection
- **‚ö° Sub-1ms L1 Cache**: Moka in-memory cache hits with get_with() coalescing
- **üî• 2-5ms L2 Cache**: Redis distributed cache v·ªõi DashMap+Mutex request coalescing
- **üõ°Ô∏è 99.6% Stampede Protection**: Prevents cache stampede in high-concurrency scenarios  
- **üîÑ Multi-threaded**: Rayon ThreadPool + tokio async runtime
- **üìä 95% Cache Coverage**: Generic cache strategies reduce API calls
- **üèóÔ∏è Service Islands**: Clean separation of concerns across 5 layers

### Benchmark Results
```
üìä Performance Test Results (16 CPU cores) - **WITH CACHE STAMPEDE PROTECTION**:

‚ö° HTTP Load Testing Results:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ                    BURST LOAD SCENARIO                         ‚îÇ  
‚îÇ üìà Peak Performance: 16,829.3 req/s (5.2ms avg latency)       ‚îÇ
‚îÇ üéØ Success Rate: 100% (0 failures across all scenarios)       ‚îÇ
‚îÇ üõ°Ô∏è Stampede Protection: 99.6% improvement vs unprotected      ‚îÇ
‚îÇ üîÑ Concurrent Clients: 100 sustained connections              ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Historical Performance Comparison:
‚Ä¢ Before Optimization:  534ms avg latency (high-concurrency)
‚Ä¢ After Route Optimization: ~13ms avg latency  
‚Ä¢ With Stampede Protection: 5.2ms avg latency (16,829+ RPS)

Multi-tier Cache Performance:
‚Ä¢ L1 Cache Hit:    <1ms (90% hit rate) + get_with() coalescing
‚Ä¢ L2 Cache Hit:  2-5ms (75% hit rate) + DashMap request deduplication  
‚Ä¢ Cache Miss:   200ms+ (single request only, others wait)
‚Ä¢ Overall Coverage: 95% (drastically reduced API calls)
```

### Service Islands Request Flow
1. **Client Request** ‚Üí Axum Router ‚Üí Layer 5 Business Logic
2. **Dashboard Island** ‚Üí Market data processing ‚Üí Layer 3 Communication
3. **Data Communication** ‚Üí PostgreSQL/Cache lookup ‚Üí Layer 2 External Services
4. **External APIs Island** ‚Üí Rate-limited API calls ‚Üí Layer 1 Infrastructure  
5. **Cache System Island** ‚Üí Generic cache strategies (L1: <1ms, L2: 2-5ms)
6. **üì§ Redis Streams Publishing** ‚Üí Market data published to stream (async, non-blocking)
7. **Response** ‚Üí Multi-tier cache storage ‚Üí Client delivery

#### Redis Streams Data Flow (NEW)
```
Layer 2 External APIs (Binance/CoinGecko/CMC)
        ‚Üì
Layer 3 Market Data Adapter
        ‚Üì
Layer 1 Cache Manager (L1 + L2 caching)
        ‚Üì
Redis Streams Publishing (XADD)
        ‚Üì
External Consumers (Python AI Service, Analytics, etc.)
```

#### Cache Strategy Mapping
- **BTC Price**: `ShortTerm` strategy (5min TTL) - Fast-changing data
- **Technical Indicators**: `LongTerm` strategy (3hr TTL) - RSI, MACD
- **Fear & Greed**: `RealTime` strategy (30s TTL) - Market sentiment
- **Global Data**: `MediumTerm` strategy (1hr TTL) - Market stats

## üõ°Ô∏è Cache Stampede Protection

### What is Cache Stampede?
Cache stampede occurs when multiple concurrent requests hit the same expired cache key simultaneously, causing all requests to fetch data from the expensive source (API calls). This can overwhelm external APIs and degrade performance.

### Our Implementation
```rust
// L1 Cache (Moka) - Built-in protection with get_with()
let data = cache.get_with(key, fetch_function).await;

// L2 Cache (Redis) - Custom DashMap+Mutex coalescing
let pending_requests = Arc<DashMap<String, Arc<Mutex<()>>>>::new();
if let Some(guard) = pending_requests.get(&key) {
    let _lock = guard.lock().await; // Wait for ongoing request
    return cache_get(&key).await;   // Get result from cache
}

// Redis Streams Integration (NEW)
// After cache update, publish to stream for external consumers
cache_manager.publish_to_stream("market_data_stream", fields, Some(1000)).await?;
```

### Performance Impact
- **üöÄ 99.6% Performance Improvement** in high-concurrency scenarios
- **‚ö° 16,829+ RPS** peak performance with 5.2ms average latency
- **üõ°Ô∏è Single API Call** per cache key expiration (vs N concurrent calls)
- **üîÑ Request Coalescing** eliminates redundant external API requests
- **üì§ Stream Publishing** adds <1ms overhead, enables real-time data pipeline

### Architecture Benefits
- **L1 Protection**: Moka's `get_with()` ensures only one computation per key
- **L2 Protection**: DashMap+Mutex prevents stampede on Redis misses  
- **Dual-Layer Defense**: Both cache levels protected independently
- **Zero Data Loss**: All requests receive the same valid result
- **üì° Stream Integration**: Cached data automatically published to Redis Streams for external consumers

## üì° API Reference

### Core Endpoints
| Method | Endpoint | Description | Performance |
|--------|----------|-------------|-------------|
| `GET` | `/` | Homepage with latest report | 16,829+ RPS |
| `GET` | `/health` | Server health check + metrics | - |
| `GET` | `/metrics` | Performance metrics | - |
| `GET` | `/crypto_report` | Latest crypto report | 16,829+ RPS |
| `GET` | `/crypto_report/:id` | Specific report by ID | 16,829+ RPS |
| `GET` | `/pdf-template/:id` | PDF-optimized report view | ‚úÖ Cached + Stampede Protected |
| `GET` | `/crypto_reports_list` | Paginated report list | - |

### Admin & Monitoring
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Server health + unified cache metrics + Redis Streams status |
| `GET` | `/cache-stats` | Detailed L1/L2 cache statistics + stream metrics |
| `POST` | `/clear-cache` | Clear all cache tiers (L1+L2) |

### Real-time & API
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/ws` | WebSocket connection for real-time updates |
| `GET` | `/api/crypto/dashboard-summary` | Cached dashboard data with crypto + US stocks (JSON) + Stream publish |
| `GET` | `/api/crypto/dashboard-summary/refresh` | Force refresh dashboard + Stream publish |

### Static Assets
| Path | Description |
|------|-------------|
| `/shared_assets/js/chart_modules.js` | Bundled chart JavaScript |
| `/shared_assets/css/` | Stylesheets |
| `/crypto_dashboard/assets/` | Dashboard-specific assets |

## üóÇÔ∏è Service Islands Cache System

H·ªá th·ªëng implement **Generic Cache Architecture** v·ªõi Layer Separation ƒë·ªÉ t√°ch bi·ªát business logic kh·ªèi cache infrastructure:

### Layer 1: Infrastructure (Generic Cache + Redis Streams)
- **L1 Cache**: `moka::future::Cache` - Ultra-fast in-memory (2000 entries, 5min TTL)
- **L2 Cache**: Redis - Distributed cache with persistence (1hr default TTL)
- **üÜï Redis Streams**: Native stream support with XADD/XREAD operations
  - `publish_to_stream()`: Publish market data to streams
  - `read_stream_latest()`: Retrieve latest N entries
  - `read_stream()`: Blocking/non-blocking stream consumption
- **Generic Strategies**: ShortTerm, MediumTerm, LongTerm, RealTime, Custom
- **Unified API**: Pure caching infrastructure, kh√¥ng business knowledge

### Layer 2: Business Logic (API-Specific + Stream Publishing)
- **Business Wrappers**: API-specific implementations using generic Layer 1
- **Strategy Mapping**: Business needs mapped to generic cache strategies
- **Cache Keys**: Business-aware cache key generation
- **üÜï Stream Integration**: Automatic stream publishing after API data fetch

### Layer 3: Communication (Enhanced with Streams)
- **üÜï Market Data Adapter**: Publishes to Redis Streams after caching
- **WebSocket Service**: Ready for stream consumer integration
- **Data Communication**: Stream-aware data routing

### Cache Architecture Benefits
- **Separation of Concerns**: Layer 1 pure caching, Layer 2 business logic
- **Extensibility**: Add new APIs ch·ªâ c·∫ßn thay ƒë·ªïi Layer 2
- **Maintainability**: Kh√¥ng hardcoded business keys trong Layer 1
- **Testability**: Layer 1 unit test ƒë·ªôc l·∫≠p, Layer 2 business logic isolated
- **üÜï Real-time Pipeline**: Redis Streams enables external consumer integration

### Cache Usage Patterns

#### 1. **Generic Cache Helper (Layer 2) + Redis Streams**
```rust
async fn cache_api_data<F, T>(
    cache_key: &str,
    strategy: CacheStrategy,  // Generic strategy
    fetch_fn: F
) -> Result<Value> {
    // Fetch and cache data
    let data = cache_manager.get_or_compute_with(key, strategy, fetch_fn).await?;
    
    // Publish to Redis Streams for external consumers
    cache_manager.publish_to_stream("market_data_stream", fields, Some(1000)).await?;
    
    Ok(data)
}
```

#### 2. **Business-Specific Wrappers (Layer 2) with Streams**
```rust
fetch_btc_price() ‚Üí cache_api_data("btc_coingecko", ShortTerm, api_call) ‚Üí Stream publish
fetch_rsi_data() ‚Üí cache_api_data("rsi_taapi", LongTerm, api_call) ‚Üí Stream publish
fetch_fear_greed() ‚Üí cache_api_data("fear_greed", RealTime, api_call) ‚Üí Stream publish
```

#### 3. **WebSocket Broadcasting (Layer 3) + Stream Consumers**
```rust
WebSocketService ‚Üí Redis pub/sub ‚Üí Real-time updates (existing)
StreamConsumer ‚Üí Redis Streams ‚Üí Python AI service (NEW)
```

#### 4. **Redis Streams Operations (Layer 1)**
```rust
// Publish to stream
let entry_id = cache_manager.publish_to_stream(
    "market_data_stream",
    vec![("btc_price".to_string(), "50000".to_string())],
    Some(1000) // Max 1000 entries
).await?;

// Read latest entries
let latest = cache_manager.read_stream_latest("market_data_stream", 10).await?;

// Blocking read for new entries
let new_entries = cache_manager.read_stream(
    "market_data_stream", 
    "$",  // Only new entries
    100,
    Some(5000)  // Block for 5 seconds
).await?;
```

### Cache Monitoring
- **Health**: `/health` endpoint shows L1/L2 status, hit rates, and Redis Streams health
- **Statistics**: `/cache-stats` provides detailed cache metrics + stream entry counts
- **Management**: `/clear-cache` clears all cache tiers
- **Performance**: 95% cache coverage, <1ms L1 hits, 2-5ms L2 hits
- **üÜï Stream Metrics**: Track published entries, consumer lag, stream throughput

üìñ **Detailed Documentation**: See [CACHE_ARCHITECTURE.md](./CACHE_ARCHITECTURE.md) for complete implementation guide.

## üöÄ Deployment

### Railway (Recommended)

#### 1. Prepare Railway Project
```bash
# Install Railway CLI
npm install -g @railway/cli

# Login and create project
railway login
railway link
```

#### 2. Setup Database
1. Go to [Railway Dashboard](https://railway.app)
2. Add PostgreSQL service from templates
3. Copy `DATABASE_URL` from Variables tab

#### 3. Deploy via GitHub (Recommended)
1. Push code to GitHub repository
2. Connect repository in Railway dashboard
3. Railway auto-detects Rust project and builds

#### 4. Configure Environment Variables
```env
DATABASE_URL=<your-postgresql-url>
AUTO_UPDATE_SECRET_KEY=<secure-secret>
TAAPI_SECRET=<crypto-api-key>
REDIS_URL=<redis-url-if-available>
HOST=0.0.0.0
PORT=8000
```

#### 5. Custom Domain (Optional)
- Add custom domain in Railway Settings

### Docker Deployment

```bash
# Build Docker image
docker build -t crypto-dashboard .

# Run with environment
docker run -p 8000:8000 \
  -e DATABASE_URL="postgresql://..." \
  -e AUTO_UPDATE_SECRET_KEY="..." \
  crypto-dashboard
```

### Production Tips
- Use `cargo build --release` for optimized builds
- Set up Redis for WebSocket features in production
- Configure reverse proxy (nginx) for SSL/domain routing
- Monitor memory usage of report cache (grows with unique report IDs accessed)

## üèóÔ∏è Project Structure (Service Islands Architecture)

```
Web-server-Report/
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îú‚îÄ‚îÄ ü¶Ä main.rs              # Server initialization + Service Islands setup
‚îÇ   ‚îú‚îÄ‚îÄ üìä performance.rs       # Performance monitoring across layers
‚îÇ   ‚îú‚îÄ‚îÄ üèóÔ∏è state.rs             # Application state + Service Islands integration
‚îÇ   ‚îî‚îÄ‚îÄ üèùÔ∏è service_islands/     # Service Islands Architecture (5 layers)
‚îÇ       ‚îú‚îÄ‚îÄ üìã mod.rs           # Service Islands module coordination
‚îÇ       ‚îú‚îÄ‚îÄ üèóÔ∏è layer1_infrastructure/     # Generic cache + shared components + Redis Streams
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ cache_system_island.rs    # L1/L2 cache + generic strategies + Redis Streams (XADD/XREAD)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ app_state_island.rs       # Unified app state with stream support
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ chart_modules_island.rs   # JavaScript bundling
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ shared_components_island.rs # Template registry + utilities
‚îÇ       ‚îú‚îÄ‚îÄ üåê layer2_external_services/   # External APIs + cache-first + stream publishing
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ external_apis_island.rs    # Binance, CoinGecko + cache-first + circuit breaker
‚îÇ       ‚îú‚îÄ‚îÄ üì° layer3_communication/       # WebSocket + data communication + streams
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ websocket_service.rs       # Real-time communication
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data_communication.rs      # Database operations + cache
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dashboard_communication.rs # Stream-aware data routing
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ layer2_adapters/           
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ market_data_adapter.rs # üÜï Publishes to Redis Streams after caching
‚îÇ       ‚îú‚îÄ‚îÄ üîç layer4_observability/       # Health monitoring + metrics + stream status
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ health_system_island.rs    # Component health + system status + stream metrics
‚îÇ       ‚îî‚îÄ‚îÄ üíº layer5_business_logic/      # Business-specific logic
‚îÇ           ‚îú‚îÄ‚îÄ dashboard_island.rs         # Market data processing
‚îÇ           ‚îî‚îÄ‚îÄ crypto_reports_island.rs    # Report management + templates
‚îú‚îÄ‚îÄ üìÅ routes/                  # Axum routes + Service Islands integration
‚îÇ   ‚îú‚îÄ‚îÄ ÔøΩ homepage.rs          # Homepage v·ªõi Crypto Reports Island
‚îÇ   ‚îú‚îÄ‚îÄ üí∞ crypto_reports.rs    # Business logic routing
‚îÇ   ‚îú‚îÄ‚îÄ üìä dashboard.rs         # Dashboard Island endpoints
‚îÇ   ‚îú‚îÄ‚îÄ üîå websocket.rs         # WebSocket Layer 3 Communication
‚îÇ   ‚îî‚îÄ‚îÄ üè• system.rs           # Layer 4 Observability endpoints
‚îú‚îÄ‚îÄ üìÅ scripts/                 # Performance testing across Service Islands
‚îÇ   ‚îú‚îÄ‚îÄ ‚ö° simple_rps_test.sh   # End-to-end RPS benchmark (500+ RPS)
‚îÇ   ‚îú‚îÄ‚îÄ üìä advanced_benchmark.sh # Service Islands performance test
‚îÇ   ‚îî‚îÄ‚îÄ üî• stress_test.sh       # Multi-layer load testing
‚îú‚îÄ‚îÄ üìÅ docs/                    # Service Islands Architecture documentation
‚îÇ   ‚îú‚îÄ‚îÄ ÔøΩÔ∏è SERVICE_ISLANDS_ARCHITECTURE.md   # 5-layer architecture guide
‚îÇ   ‚îú‚îÄ‚îÄ üîÑ SERVICE_ISLANDS_WORKFLOW.md        # Development workflow
‚îÇ   ‚îú‚îÄ‚îÄ üóÇÔ∏è GENERIC_CACHE_ARCHITECTURE.md     # Layer separation cache
‚îÇ   ‚îî‚îÄ‚îÄ ÔøΩ WEBSOCKET_REALTIME_IMPLEMENTATION.md # Layer 3 communication
‚îú‚îÄ‚îÄ üìÅ dashboards/              # Templates v·ªõi Layer 1 shared components
‚îÇ   ‚îú‚îÄ‚îÄ üè† home.html            # Homepage template
‚îÇ   ‚îî‚îÄ‚îÄ ÔøΩ crypto_dashboard/    # Business logic templates
‚îú‚îÄ‚îÄ üìÅ shared_assets/           # Layer 1 shared components
‚îÇ   ‚îú‚îÄ‚îÄ üé® css/                # Global stylesheets
‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è js/chart_modules/   # Modular chart components
‚îú‚îÄ‚îÄ ‚öôÔ∏è Cargo.toml              # Dependencies (moka, redis, dashmap, rayon)
‚îú‚îÄ‚îÄ üê≥ Dockerfile              # Container v·ªõi Service Islands
‚îú‚îÄ‚îÄ üöÇ railway.json           # Railway deployment config
‚îî‚îÄ‚îÄ üìã .env.example           # Environment template v·ªõi layer configs
```

### Service Islands Code Organization
- **Layer 5 ‚Üí Layer 1**: Top-down dependency flow
- **Generic Layer 1**: Pure infrastructure, kh√¥ng business knowledge
- **Business Layer 2**: API-specific implementations using generic Layer 1
- **Clear Boundaries**: M·ªói island ƒë·ªôc l·∫≠p, interface r√µ r√†ng
- **Testable Architecture**: Unit test t·ª´ng layer independently

## ÔøΩ Redis Streams Integration

### Overview
Redis Streams ƒë∆∞·ª£c t√≠ch h·ª£p v√†o Layer 1 Infrastructure v√† s·ª≠ d·ª•ng qua Layer 3 Communication ƒë·ªÉ t·∫°o real-time data pipeline cho external consumers (Python AI service, analytics, monitoring).

### Architecture Flow
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 2: External APIs (Binance, CoinGecko, CMC)         ‚îÇ
‚îÇ  ‚Ä¢ Fetch market data from multiple sources                ‚îÇ
‚îÇ  ‚Ä¢ Circuit breaker + fallback logic                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 3: Market Data Adapter                              ‚îÇ
‚îÇ  ‚Ä¢ Normalize data format                                   ‚îÇ
‚îÇ  ‚Ä¢ Cache with RealTime strategy (10s TTL)                 ‚îÇ
‚îÇ  ‚Ä¢ Publish to Redis Streams (market_data_stream)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 1: Cache Manager + Redis Streams                    ‚îÇ
‚îÇ  ‚Ä¢ L1 Cache (moka): In-memory, <1ms                       ‚îÇ
‚îÇ  ‚Ä¢ L2 Cache (Redis): Distributed, 2-5ms                   ‚îÇ
‚îÇ  ‚Ä¢ Redis Streams: XADD publish, auto-trim at 1000 entries ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Web Clients ‚îÇ         ‚îÇ External         ‚îÇ
‚îÇ (REST API)  ‚îÇ         ‚îÇ Consumers        ‚îÇ
‚îÇ             ‚îÇ         ‚îÇ ‚Ä¢ Python AI      ‚îÇ
‚îÇ             ‚îÇ         ‚îÇ ‚Ä¢ Analytics      ‚îÇ
‚îÇ             ‚îÇ         ‚îÇ ‚Ä¢ Monitoring     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Features

#### 1. **Automatic Publishing**
```rust
// Market data automatically published after caching
match cache_manager.publish_to_stream(
    "market_data_stream",
    fields,  // Flattened JSON key-value pairs
    Some(1000)  // Auto-trim at 1000 entries
).await {
    Ok(entry_id) => println!("üì§ Published to stream: {}", entry_id),
    Err(e) => println!("‚ö†Ô∏è Stream publish failed (non-critical): {}", e)
}
```

#### 2. **Consumer-Ready Format**
```rust
// JSON data ‚Üí Flattened stream fields
{
  "btc_price_usd": 50000.0,
  "eth_price_usd": 3000.0
}
‚Üì
[
  ("btc_price_usd", "50000.0"),
  ("eth_price_usd", "3000.0")
]
```

#### 3. **Stream Operations**
```rust
// Read latest N entries (newest first)
let latest = cache_manager.read_stream_latest("market_data_stream", 10).await?;

// Blocking read for new entries only
let new_data = cache_manager.read_stream(
    "market_data_stream",
    "$",        // Only new entries
    100,        // Max count
    Some(5000)  // Block for 5 seconds
).await?;
```

#### 4. **Python Consumer Example**
```python
import redis
import json

r = redis.Redis(host='localhost', port=6379, decode_responses=True)

# Read latest 10 entries
entries = r.xrevrange('market_data_stream', count=10)

for entry_id, fields in entries:
    data = dict(fields)
    print(f"Entry {entry_id}: BTC=${data.get('btc_price_usd')}")

# Blocking read for real-time updates
while True:
    entries = r.xread({'market_data_stream': '$'}, block=5000, count=1)
    for stream, messages in entries:
        for entry_id, fields in messages:
            print(f"New data: {dict(fields)}")
```

### Performance Characteristics
- **üì§ Publish Latency**: <1ms (non-blocking XADD)
- **üìä Throughput**: 10,000+ entries/second sustained
- **üíæ Memory**: Auto-trim at 1000 entries (~200KB typical)
- **üîÑ Consumer Lag**: Sub-second for Python consumers
- **üõ°Ô∏è Fault Tolerance**: Stream failures don't affect core API

### Monitoring
```bash
# Check stream info
redis-cli XINFO STREAM market_data_stream

# Read latest entry
redis-cli XREVRANGE market_data_stream + - COUNT 1

# Monitor stream length
redis-cli XLEN market_data_stream
```

### Use Cases
1. **Python AI Service**: Real-time market data for ML models
2. **Analytics Pipeline**: Stream data to data warehouse
3. **Monitoring Dashboards**: External monitoring tools
4. **Backup Systems**: Asynchronous data replication
5. **Audit Logging**: Track all market data updates

### Configuration
```env
# Redis connection (default: localhost:6379)
REDIS_URL=redis://localhost:6379

# Stream settings (configured in code)
STREAM_NAME=market_data_stream
MAX_STREAM_LENGTH=1000
```

---

## ÔøΩüîß Development & Troubleshooting

### Development Setup
```bash
# Enable debug logging
export DEBUG=1

# Watch for changes (requires cargo-watch)
cargo install cargo-watch
cargo watch -x run

# Run performance benchmarks
./scripts/simple_rps_test.sh       # Quick RPS test (500+ RPS)
./scripts/advanced_benchmark.sh    # Comprehensive benchmark
./scripts/stress_test.sh           # Load testing

# Run tests
cargo test

# Test API integrations
./test-finnhub-integration.sh       # Test US stock indices integration
cargo run --example test_coinmarketcap_fallback  # Test crypto fallback
cargo run --example test_finnhub_integration     # Test Finnhub API

# Check code quality
cargo clippy
cargo fmt
```

### Common Issues & Solutions

#### üîç Database Connection Issues
```bash
# Check PostgreSQL connection
psql $DATABASE_URL -c "SELECT version();"

# Verify table exists
psql $DATABASE_URL -c "\dt"
```

#### ‚ö° Performance Debugging
- Check cache hit rates in server logs
- Monitor memory usage: `ps aux | grep web-server-report`
- Use `DEBUG=1` for detailed request logging

#### üîÑ Cache Issues + Stampede Protection + Redis Streams
- **L1 Cache**: In-memory cache auto-expires after 5 minutes with get_with() protection
- **L2 Cache**: Redis cache expires after 1 hour v·ªõi DashMap+Mutex stampede protection
- **Stampede Protection**: DashMap tracks pending requests, prevents multiple API calls
- **üÜï Redis Streams**: Auto-trimming at 1000 entries, no manual cleanup needed
- **Cache Clearing**: Use `/clear-cache` endpoint to clear all tiers (L1+L2)
- **Cache Stats**: Monitor hit rates v√† stampede metrics via `/health` and `/cache-stats`
- **üÜï Stream Monitoring**: Check stream entry count and consumer lag in `/health`
- **Restart server**: Clears L1 cache, L2 persists, Streams retain last 1000 entries: `pkill web-server-report && cargo run`

#### üöÄ Build Optimization
```bash
# Faster debug builds
export CARGO_PROFILE_DEV_DEBUG=0

# Smaller release builds  
cargo build --release
strip target/release/web-server-report
```

### Monitoring & Metrics
- Health check: `curl http://localhost:8000/health`
- Performance metrics: `curl http://localhost:8000/metrics` 
- **Multi-tier cache stats**: `curl http://localhost:8000/cache-stats`
- **Cache management**: `curl -X POST http://localhost:8000/clear-cache`
- **HTTP Load Testing**: Run benchmark to validate 16,829+ RPS performance
- WebSocket status: Check Redis connection logs
- **L1 cache metrics**: Monitor moka cache hit rate v√† stampede protection
- **L2 cache status**: Redis health v√† DashMap request coalescing metrics
- **üÜï Redis Streams metrics**: Monitor stream entry count, publish rate, consumer lag
- **üÜï Stream debugging**: `redis-cli XINFO STREAM market_data_stream` to inspect stream details
- Response times: Enable `DEBUG=1` for timing logs v·ªõi stampede tracking

## üéØ Recent Updates

### ‚úÖ Redis Streams Integration (Latest - October 2025)
- **üì§ Native Stream Publishing**: Market data automatically published to `market_data_stream`
- **üîÑ Python AI Service Integration**: External consumers can read real-time market data
- **‚ö° Sub-millisecond Overhead**: Stream publishing adds <1ms latency
- **üõ°Ô∏è Non-blocking Architecture**: Stream failures don't affect core functionality
- **üìä Auto-trimming**: Streams maintain last 1000 entries automatically
- **üéØ Consumer-ready Format**: Flattened JSON fields optimized for XREAD consumers

### ‚úÖ Layer Architecture Refactoring (October 2025)
- **üèùÔ∏è Layer 1 Enhancements**: Cache Manager with Redis Streams methods
- **üåê Layer 2 Improvements**: External APIs Island with stream publishing
- **üì° Layer 3 Upgrades**: Market Data Adapter publishes to streams after caching
- **üîß Modular Design**: Each layer clearly separated with well-defined interfaces

### ‚úÖ Cache Stampede Protection Implementation
- **üõ°Ô∏è DashMap+Mutex Request Coalescing**: Prevents multiple concurrent API calls for same cache key
- **‚ö° Moka get_with() L1 Protection**: Built-in stampede protection for in-memory cache
- **üìà 99.6% Performance Improvement**: From 534ms ‚Üí 5.2ms average latency in high-concurrency
- **üöÄ 16,829+ RPS Peak Performance**: Sustained high throughput with stampede protection
- **üîÑ Request Deduplication**: Single API call per cache expiration across all concurrent requests

### üîß HTTP Endpoint Optimizations  
- **Route-level Optimization**: Removed unnecessary `fetch_realtime_market_data()` calls
- **Template Caching**: Cached HTML templates with business logic separation
- **Background Processing**: spawn_blocking for CPU-intensive operations
- **Connection Pooling**: Optimized PostgreSQL pool for 16-core systems

### üìä Comprehensive Load Testing
- **Multi-scenario Benchmarking**: Gradual ramp-up, sustained load, burst scenarios
- **100% Success Rate**: Zero failures across 16,829+ requests per second
- **Atomic Counters**: Thread-safe performance metrics collection
- **Real-world Testing**: Production-like concurrent load validation

---

üéâ **Ready for Production**: High-performance crypto dashboard with enterprise-grade caching and stampede protection!

## ü§ù Contributing

### Code Style
- Use `cargo fmt` for formatting
- Follow Rust naming conventions
- Add documentation for public functions
- Include error handling with proper logging

### Adding New Features
1. Fork the repository
2. Create feature branch: `git checkout -b feature/new-feature`
3. Add tests for new functionality
4. Submit pull request with description

### Performance Guidelines
- Prefer `tokio::join!` for concurrent operations
- Use `DashMap` for thread-safe shared state with high concurrency
- Use `AtomicUsize` for lock-free counters and metrics
- Cache expensive operations (DB queries, template rendering)
- Use `spawn_blocking` for CPU-intensive background tasks
- Add appropriate HTTP cache headers
- Benchmark with `./scripts/simple_rps_test.sh` after changes

## üìú License & Support

**License**: Apache License 2.0 - see LICENSE file for details

**Support**:
- üêõ Bug reports: [Create GitHub Issue](https://github.com/thichuong/Web-server-Report/issues)
- üí° Feature requests: [GitHub Discussions](https://github.com/thichuong/Web-server-Report/discussions)
- üìß Contact: [Your Email]

**Related Projects**:
- ü§ñ [Crypto-Dashboard-and-AI-ReportGenerator](https://github.com/thichuong/Crypto-Dashboard-and-AI-ReportGenerator) - Admin UI & AI report generation

---

‚≠ê **Star this repo** if it helps you build better crypto dashboards! 

Built with ‚ù§Ô∏è using Rust ü¶Ä

